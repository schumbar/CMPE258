{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOIJ7gavkbqCClMSz4YFWqt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schumbar/CMPE258/blob/chumbar%2Fassignment_02/assignment_02/CMPE258_assignment02_part_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CMPE 258 Assignment 02 - Part C: Code Interpretter\n",
        "\n",
        "By Shawn Chumbar"
      ],
      "metadata": {
        "id": "IwwTF8yDVeG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment Description\n",
        "In this assignment, we are tasked with replicating a series of experiments conducted with closed and open-source Language Model Models (LLMs) as presented in the references section.\n",
        "\n",
        "Your primary objective is to replicate the experiments and modify them to perform alternative tasks. Instead of using the provided SQL dataset, you will be utilizing different datasets available at [Hugging Face](https://huggingface.co/knowrohit07) to demonstrate your adaptability and creativity.\n",
        "\n",
        "This portion is for the Tokenization portion of the assignment.\n",
        "\n",
        "#### Tasks:\n",
        "1. Reproduce the experiments showcased in the provided YouTube videos, ensuring that you implement all aspects such as prompt-based generation, fine-tuning, Retrieval-Augmented Generation (RAG), local interpreter, function calling, and llama.cpp CPU inference.\n",
        "\n",
        "2. Creatively adapt the Colab notebooks from the YouTube videos to highlight innovative use cases and applications of LLMs.\n",
        "\n",
        "3. If necessary, make the required adjustments to the Colab notebooks to ensure they function correctly. Document these modifications in detail.\n",
        "\n",
        "4. Produce a demonstration video that showcases the functionality of your modified Colab notebooks and your innovative use cases. Ensure the video is linked in your documentation.\n",
        "\n",
        "Please note that it is essential to reference the summarized versions of the YouTube videos available at [Summarize.tech](https://www.summarize.tech/) as they provide an overview of the content and serve as a starting point for your experiments.\n",
        "\n",
        "Your assignment should reflect your ability to replicate and creatively extend the experiments, as well as your capacity to document and present your work effectively. Please feel free to reach out if you encounter any issues with the Colab notebooks that require minor adjustments.\n",
        "\n",
        "### References Used\n",
        "1. [A Hackers' Guide to Language Models](https://www.youtube.com/watch?v=jkrNMKz9pWU): This video showcases various experiments using LLMs.\n",
        "2. [A hacker's guide to open source LLMs - posit::conf(2023)](https://www.youtube.com/watch?v=sYliwvml9Es): This video provides additional insights into LLMs.\n",
        "3. [Summary of A Hackers' Guide to Language Models](https://www.summarize.tech/www.youtube.com/watch?v=jkrNMKz9pWU): Summarized version video titled \"A Hackers' Guide to Language Models\".\n",
        "4. [Summary of A hacker's guide to open source LLMs - posit::conf(2023)](https://www.summarize.tech/www.youtube.com/watch?v=sYliwvml9Es): Summarized version of video titled \"Summary of A hacker's guide to open source LLMs - posit::conf(2023)\".\n",
        "5. [Hugging Face Datasets](https://huggingface.co/knowrohit07): Alternative datasets for experiments."
      ],
      "metadata": {
        "id": "lXUyT_ogVIZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "jS7avoUcYaOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWefJQ1ckWqC",
        "outputId": "b0fba352-535c-4346-ea03-6ac80a80b6ce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28.0\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.0) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.0) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.0) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9mfeaai0kon8",
        "outputId": "9a5372ca-3e05-4b51-fafa-6a8f2936ad6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tokenize, ast\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "vBCX-4BbZDKt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "RHxCSEDhkroP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = api_key"
      ],
      "metadata": {
        "id": "2pylWxKU_gZW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import create_model\n",
        "import inspect, json\n",
        "from inspect import Parameter\n",
        "from openai import ChatCompletion,Completion\n"
      ],
      "metadata": {
        "id": "JaYdwrRZaeFI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The OpenAI API"
      ],
      "metadata": {
        "id": "ZTlPkB6QYjiw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Function Declarations"
      ],
      "metadata": {
        "id": "BWmDW3EAaMMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def response(compl): print(c.choices[0].message.content)"
      ],
      "metadata": {
        "id": "9CqN8VtdaLqg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_content_only(result):\n",
        "  return result.choices[0].message.content"
      ],
      "metadata": {
        "id": "YK60WAF5aHfk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def askgpt(user, system=None, model=\"gpt-3.5-turbo\", **kwargs):\n",
        "    msgs = []\n",
        "    if system: msgs.append({\"role\": \"system\", \"content\": system})\n",
        "    msgs.append({\"role\": \"user\", \"content\": user})\n",
        "    return ChatCompletion.create(model=model, messages=msgs, **kwargs)"
      ],
      "metadata": {
        "id": "s0bfLxwRaHdP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_api(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    msgs = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    try: return client.chat.completions.create(model=model, messages=msgs)\n",
        "    except openai.error.RateLimitError as e:\n",
        "        retry_after = int(e.headers.get(\"retry-after\", 60))\n",
        "        print(f\"Rate limit exceeded, waiting for {retry_after} seconds...\")\n",
        "        time.sleep(retry_after)\n",
        "        return call_api(params, model=model)"
      ],
      "metadata": {
        "id": "qq2CnUvkaHap"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sums(a:int, b:int=1):\n",
        "    \"Adds a + b\"\n",
        "    return a + b"
      ],
      "metadata": {
        "id": "4EiFSptLaafu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiply(a:int, b:int):\n",
        "    \"multiply a * b\"\n",
        "    return a * b"
      ],
      "metadata": {
        "id": "QwdumooiABp_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def schema(f):\n",
        "    kw = {n:(o.annotation, ... if o.default==Parameter.empty else o.default)\n",
        "          for n,o in inspect.signature(f).parameters.items()}\n",
        "    s = create_model(f'Input for `{f.__name__}`', **kw).schema()\n",
        "    return dict(name=f.__name__, description=f.__doc__, parameters=s)"
      ],
      "metadata": {
        "id": "zmNvaKJWaadX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_func(c):\n",
        "    fc = c.choices[0].message.function_call\n",
        "    if fc.name not in funcs_ok: return print(f'Not allowed: {fc.name}')\n",
        "    f = globals()[fc.name]\n",
        "    return f(**json.loads(fc.arguments))"
      ],
      "metadata": {
        "id": "uOLPkFBraaaw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(code):\n",
        "    tree = ast.parse(code)\n",
        "    last_node = tree.body[-1] if tree.body else None\n",
        "\n",
        "    # If the last node is an expression, modify the AST to capture the result\n",
        "    if isinstance(last_node, ast.Expr):\n",
        "        tgts = [ast.Name(id='_result', ctx=ast.Store())]\n",
        "        assign = ast.Assign(targets=tgts, value=last_node.value)\n",
        "        tree.body[-1] = ast.fix_missing_locations(assign)\n",
        "\n",
        "    ns = {}\n",
        "    exec(compile(tree, filename='<ast>', mode='exec'), ns)\n",
        "    return ns.get('_result', None)"
      ],
      "metadata": {
        "id": "bH4iD0z5aaYa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def python(code:str):\n",
        "    return run(code)"
      ],
      "metadata": {
        "id": "gfA3wl-FaspX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "98e86e7d-64f0-411d-bfce-289b06174dd4"
      },
      "source": [
        "#### Code Interpretter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "d9af1e46-c560-4bc9-a6a7-78fafb2dfc78",
        "outputId": "f878e210-de1b-4efc-d1aa-453703251fc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'sums',\n",
              " 'description': 'Adds a + b',\n",
              " 'parameters': {'properties': {'a': {'title': 'A', 'type': 'integer'},\n",
              "   'b': {'default': 1, 'title': 'B', 'type': 'integer'}},\n",
              "  'required': ['a'],\n",
              "  'title': 'Input for `sums`',\n",
              "  'type': 'object'}}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "schema(sums)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1d60dcd4-514f-4efd-8b4a-fafac92c7453"
      },
      "outputs": [],
      "source": [
        "c = askgpt(\"Use the `sum` function to solve this: What is 6+3?\",\n",
        "           system = \"You must use the `sum` function instead of adding yourself.\",\n",
        "           functions=[schema(sums)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5cc8a9eb-64fc-4ce3-9f93-aee334fc8c65",
        "outputId": "a28b9706-2b2b-4ed7-e65b-46a07e850da0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject at 0x79e386bef420> JSON: {\n",
              "  \"role\": \"assistant\",\n",
              "  \"content\": null,\n",
              "  \"function_call\": {\n",
              "    \"name\": \"sums\",\n",
              "    \"arguments\": \"{\\\"a\\\":6,\\\"b\\\":3}\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "m = c.choices[0].message\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5a881835-83a2-4fbc-9796-409831dcdb36",
        "outputId": "88d6c982-85bc-40d4-facd-83808af914ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"a\":6,\"b\":3}\n"
          ]
        }
      ],
      "source": [
        "k = m.function_call.arguments\n",
        "print(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "3f32b172-7730-4c58-a999-5d3800e8c2a4"
      },
      "outputs": [],
      "source": [
        "funcs_ok = {'sums', 'python'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ce6be825-44fa-4bc9-a83a-7ecbcb6c2729",
        "outputId": "07e4d6f5-c293-4ebd-c948-ccc2655604a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "call_func(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "37aa6983-d9af-40e8-b438-ed8573399020",
        "outputId": "b59ab43c-18ca-4ed9-f8ff-dc1fe972474b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "run(\"\"\"\n",
        "a=1\n",
        "b=2\n",
        "a+b\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pWg-ITLMAnOm"
      },
      "outputs": [],
      "source": [
        "c = askgpt(\"Use the `multiply` function to solve this: What is 6*3?\",\n",
        "           system = \"You must use the `sum` function instead of adding yourself.\",\n",
        "           functions=[schema(multiply)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "outputId": "262adfa6-1398-4d6d-c9be-23b6c82cd5cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGRGzrFQAnOm"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject at 0x79e369973510> JSON: {\n",
              "  \"role\": \"assistant\",\n",
              "  \"content\": null,\n",
              "  \"function_call\": {\n",
              "    \"name\": \"multiply\",\n",
              "    \"arguments\": \"{\\\"a\\\":6,\\\"b\\\":3}\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "m = c.choices[0].message\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "outputId": "83f1d25a-c5ae-4eb9-8a7e-83e617f8316e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzWIb940AnOm"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"a\":6,\"b\":3}\n"
          ]
        }
      ],
      "source": [
        "k = m.function_call.arguments\n",
        "print(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tuy6EIyWAnOm"
      },
      "outputs": [],
      "source": [
        "funcs_ok = {'sums', 'multiply', 'python'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "outputId": "00cf30fd-518b-41e8-dd74-c7a83b65f075",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGktE6GcAnOn"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "call_func(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "outputId": "14f8d641-9152-4101-ba4b-cae8be1e3ab3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI415ackAnOn"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "run(\"\"\"\n",
        "a=1\n",
        "b=2\n",
        "a*b\n",
        "\"\"\")"
      ]
    }
  ]
}